{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests for Build_OBM\n",
    "This file is meant to test out individual code before scripting in the main repo. Do not use for running the occupant behavior model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import csv\n",
    "import pickle\n",
    "from tools_ipynb import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a DyD file\n",
    "df = pd.read_csv(\"C:/devel/Build_OBM/data/home_1.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varInfo_1 = {'Unnamed: 0': 'DateTime' ,'Event': 'event' ,'Humidity': 'hum' ,'HumidityExpectedHigh': 'humExpHi' ,'HumidityExpectedLow': 'humExpLo' ,'RH_out': 'RH_out' ,'Remote_Sensor_1_Motion': 'RS1Mo' ,'Remote_Sensor_1_Temperature [oF]': 'RS1T' ,'Remote_Sensor_2_Motion': 'RS2Mo' ,'Remote_Sensor_2_Temperature [oF]': 'RS2T','Remote_Sensor_3_Motion': 'RS3Mo' ,'Remote_Sensor_3_Temperature [oF]': 'RS3T' ,'Remote_Sensor_4_Motion': 'RS4Mo' ,'Remote_Sensor_4_Temperature [oF]': 'RS4T' ,'Remote_Sensor_5_Motion': 'RS5Mo' ,'Remote_Sensor_5_Temperature [oF]': 'RS5T' ,'Remote_Sensor_6_Motion': 'RS6Mo' ,'Remote_Sensor_6_Temperature [oF]': 'RS6T' ,'Remote_Sensor_7_Motion': 'RS7Mo' ,'Remote_Sensor_7_Temperature [oF]': 'RS7T' ,'Remote_Sensor_8_Motion': 'RS8Mo' ,'Remote_Sensor_8_Temperature [oF]': 'RS8T','Remote_Sensor_9_Motion': 'RS9T' ,'Remote_Sensor_9_Temperature [oF]': 'RS9Mo' ,'Remote_Sensor_10_Motion': 'RS10T' ,'Remote_Sensor_10_Temperature [oF]': 'RS10Mo' ,'Remote_Sensor_11_Motion': 'RS11T' ,'Remote_Sensor_11_Temperature [oF]': 'RS11Mo' ,'Remote_Sensor_12_Motion': 'RS12T' ,'Remote_Sensor_12_Temperature [oF]': 'RS12Mo' ,'Remote_Sensor_13_Motion': 'RS13T' ,'Remote_Sensor_13_Temperature [oF]': 'RS13Mo' ,'Schedule': 'schedule' ,'T_ctrl [oF]': 'T_ctrl' ,'T_out [oF]': 'T_out' ,'T_stp_cool [oF]': 'T_stp_cool' ,'T_stp_heat [oF]': 'T_stp_heat' ,'Thermostat_Motion': 'TSMo' ,'Thermostat_Temperature [oF]': 'TST' ,'auxHeat1 [sec]': 'auxHeat1' ,'auxHeat2 [sec]': 'auxHeat2' ,'auxHeat3 [sec]': 'auxHeat3' ,'compCool1 [sec]': 'cmpCool1' ,'compCool2 [sec]': 'cmpCool2' ,'compCool3 [sec]': 'cmpCool3' ,'compHeat1 [sec]': 'cmpHeat1' ,'compHeat2 [sec]': 'cmpHeat2' ,'compHeat3 [sec]': 'cmpHeat3' ,'dehumidifier': 'dehumidifier','fan [sec]': 'fan' ,'humidifier': 'humidifier' ,'ventilator': 'ventilator'}\n",
    "varInfo = { 'Header in CSV':['Unnamed: 0', 'Event','Humidity', 'HumidityExpectedHigh', 'HumidityExpectedLow','RH_out','Remote_Sensor_1_Motion','Remote_Sensor_1_Temperature [oF]','Remote_Sensor_2_Motion','Remote_Sensor_2_Temperature [oF]','Remote_Sensor_3_Motion','Remote_Sensor_3_Temperature [oF]',\n",
    "'Remote_Sensor_4_Motion', 'Remote_Sensor_4_Temperature [oF]', 'Remote_Sensor_5_Motion', 'Remote_Sensor_5_Temperature [oF]', 'Remote_Sensor_6_Motion', 'Remote_Sensor_6_Temperature [oF]', 'Remote_Sensor_7_Motion', 'Remote_Sensor_7_Temperature [oF]', 'Remote_Sensor_8_Motion', 'Remote_Sensor_8_Temperature [oF]',\n",
    "'Remote_Sensor_9_Motion', 'Remote_Sensor_9_Temperature [oF]', 'Remote_Sensor_10_Motion', 'Remote_Sensor_10_Temperature [oF]', 'Remote_Sensor_11_Motion', 'Remote_Sensor_11_Temperature [oF]', 'Remote_Sensor_12_Motion', 'Remote_Sensor_12_Temperature [oF]', 'Remote_Sensor_13_Motion', 'Remote_Sensor_13_Temperature [oF]',\n",
    "'Schedule', 'T_ctrl [oF]', 'T_out [oF]', 'T_stp_cool [oF]', 'T_stp_heat [oF]', 'Thermostat_Motion', 'Thermostat_Temperature [oF]', 'auxHeat1 [sec]', 'auxHeat2 [sec]', 'auxHeat3 [sec]', 'compCool1 [sec]', 'compCool2 [sec]', 'compCool3 [sec]', 'compHeat1 [sec]', 'compHeat2 [sec]', 'compHeat3 [sec]', 'dehumidifier', 'fan [sec]',\n",
    "'humidifier', 'ventilator'],\n",
    " 'VariableName':['DateTime', 'event', 'hum', 'humExpHi','humExpLo' ,'RH_out' ,'RS1Mo' ,'RS1T' ,'RS2Mo' ,'RS2T' ,'RS3Mo' ,'RS3T' ,'RS4Mo' ,'RS4T' ,'RS5Mo' ,'RS5T' ,'RS6Mo' ,'RS6T' ,'RS7Mo' ,'RS7T' ,'RS8Mo' ,'RS8T',\n",
    " 'RS9Mo', 'RS9T' ,'RS10Mo' ,'RS10T' ,'RS11Mo' ,'RS11T' ,'RS12Mo' ,'RS12T' ,'RS13Mo' ,'RS13T' ,'schedule' ,'T_ctrl' ,'T_out' ,'T_stp_cool' ,'T_stp_heat' ,'TSMo' ,'TST' ,'auxHeat1' ,'auxHeat2' ,'auxHeat3' ,'cmpCool1' ,'cmpCool2' ,'cmpCool3' ,'cmpHeat1' ,'cmpHeat2' ,'cmpHeat3' ,'dehumidifier' ,'fan' ,'humidifier' ,'ventilator'],\n",
    " 'Type':['datetime', 'categorical', 'double', 'double','float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'categorical' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float'],\n",
    " 'Unit':['', '', '%', '%','%' ,'%' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'oF' ,'oF' ,'oF' ,'' ,'F' ,'s' ,'s' ,'s' ,'s' ,'s' ,'s' ,'s' ,'s' ,'s' ,'' ,'s' ,'' ,''],\n",
    " 'Description':['Date and time that the reading was taken', 'Anything that modifies the schedule (e.g. A temperature hold, demand response event, Vacation, SmartRecovery feature)',\n",
    "                'Indoor humidity (in RH%)', 'Setpoint (for users who have a Humidifier) (in RH%)','Setpoint (for users who have a Humidifier) (in RH%)' ,'' ,'Detects motion (binary) at that date/time at the remote sensor 1' ,'Indoor temperature measurement at the remote sensor 1' ,'Detects motion (binary) at that date/time at the remote sensor 2' ,'Indoor temperature measurement at the remote sensor 2' ,'Detects motion (binary) at that date/time at the remote sensor 3' ,'Indoor temperature measurement at the remote sensor 3' ,'Detects motion (binary) at that date/time at the remote sensor 4' ,'Indoor temperature measurement at the remote sensor 4' ,'Detects motion (binary) at that date/time at the remote sensor 5' ,'Indoor temperature measurement at the remote sensor 5' ,'Detects motion (binary) at that date/time at the remote sensor 6' ,'Indoor temperature measurement at the remote sensor 6' ,'Detects motion (binary) at that date/time at the remote sensor 7' ,'Indoor temperature measurement at the remote sensor 7' ,'Detects motion (binary) at that date/time at the remote sensor 8' ,'Indoor temperature measurement at the remote sensor 8' ,'Detects motion (binary) at that date/time at the remote sensor 9' ,'Indoor temperature measurement at the remote sensor 9' ,'Detects motion (binary) at that date/time at the remote sensor 10' ,'Indoor temperature measurement at the remote sensor 10' ,'Detects motion (binary) at that date/time at the remote sensor 11' ,'Indoor temperature measurement at the remote sensor 11' ,'Detects motion (binary) at that date/time at the remote sensor 12' ,'Indoor temperature measurement at the remote sensor 12' ,'Detects motion (binary) at that date/time at the remote sensor 13' ,'Indoor temperature measurement at the remote sensor 13' ,'Fields include things like Vacation, Sleep, Away, Nap, etc. which are user-defined descriptors for desired set points against activity/behaviour' ,'Average indoor temperature based on relevant sensors as defined by the schedule or mode the user is in' ,'Outdoor temperate for nearest weather station' ,'Indoor cool setpoint' ,'Indoor heat setpoint' ,'Detects motion (binary) at that date/time' ,'Indoor measurement at the thermostat (I.e. Not remote sensor)' ,'Runtime (seconds) of stage 1 of any heat source other than a heat pump' ,'Runtime (seconds) of stage 2 of any heat source other than a heat pump' ,'Runtime (seconds) of stage 3 of any heat source other than a heat pump' ,'Runtime (seconds) for any cooling stage 1' ,'Runtime (seconds) for any cooling stage 2' ,'Runtime (seconds) for any cooling stage 3' ,'Runtime (seconds) for stage 1 of heat-pumps used in heating' ,'Runtime (seconds) for stage 2 of heat-pumps used in heating' ,'Runtime (seconds) for stage 3 of heat-pumps used in heating' ,'' ,'Runtime (seconds) for fan' ,'' ,'']}\n",
    "df_var = pd.DataFrame.from_dict(varInfo)\n",
    "df_var.set_index('Header in CSV',inplace=True)\n",
    "columns2replace = df_var['VariableName'].to_dict()\n",
    "df = df.rename(columns=columns2replace)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add motion column that aggregates all motion data into a boolean value\n",
    "def agg_data(columns,row):\n",
    "    return row[columns].any()\n",
    "\n",
    "motion_colmns =[x for x in df.columns if 'Mo' in x]\n",
    "df['mo'] = df.apply(lambda row: agg_data(motion_colmns,row), axis=1)\n",
    "heating_equip_columns = ['auxHeat1' ,'auxHeat2' ,'auxHeat3','cmpHeat1' ,'cmpHeat2' ,'cmpHeat3']\n",
    "cooling_equip_columns = ['cmpCool1' ,'cmpCool2' ,'cmpCool3']\n",
    "heat_colmns = [x for x in df.columns if x in heating_equip_columns]\n",
    "cool_colmns = [x for x in df.columns if x in cooling_equip_columns]\n",
    "\n",
    "# 'auxHeat1' ,'auxHeat2' ,'auxHeat3' ,'cmpCool1' ,'cmpCool2' ,'cmpCool3' ,'cmpHeat1' ,'cmpHeat2' ,'cmpHeat3' \n",
    "df['equip_run_heat'] = df.apply(lambda row: agg_data(heat_colmns,row), axis=1)\n",
    "df['equip_run_cool'] = df.apply(lambda row: agg_data(cool_colmns,row), axis=1)\n",
    "# Change string series to datetime series\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df['schedule'] = df['schedule'].astype(\"category\")\n",
    "df['event'] = df['event'].astype(\"category\")\n",
    "df_new = df.copy()\n",
    "cols_2_keep = ['DateTime', 'schedule', 'event', 'T_ctrl', 'T_stp_cool', 'T_stp_heat',\n",
    "       'hum', 'T_out', 'equip_run_heat','equip_run_cool', 'fan','mo']\n",
    "df_new.drop(df_new.columns.difference(cols_2_keep), 1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/read to/from hdf5 format for easy load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_hdf('sample_data1.h5', key='df_new', mode='w',format=\"table\")\n",
    "del [[df,df_new]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_hdf('sample_data1.h5')\n",
    "df_read.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Visualize setpoint data prior to cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idx = 0\n",
    "e_idx = 100\n",
    "f,axes = plt.subplots(3,1)\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_stp_cool'],label='cool', ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_stp_heat'],label='heat',ax = axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_ctrl'],label='T_in',ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_out'],label='T_out',ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['equip_run_cool'],label='cool_equip',ax =axes[1])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['equip_run_heat'],label='heat_equip', ax=axes[1])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['mo'],label='heat_equip', ax=axes[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_setpoints(df,column):\n",
    "    idx_DSP = df[df[column].diff() != 0].index.values\n",
    "    idx_DSP_diff = np.diff(idx_DSP)\n",
    "    idxes_2_begin = []\n",
    "    idxes_2_end = []\n",
    "    temp_idx = -1\n",
    "    # Iterate over the difference of index values were dsp was found\n",
    "    for idx, diff_value in enumerate(idx_DSP_diff):\n",
    "        if idx <= temp_idx:\n",
    "            continue\n",
    "        \n",
    "        # If the DSPs exists closely\n",
    "        if diff_value < 3:\n",
    "\n",
    "            idx_2_begin = idx_DSP[idx]\n",
    "            idx_2_end = idx_DSP[idx+1]\n",
    "            # Scan when the last consecutive DSP occurs\n",
    "            for next_idx, next_idx_diff in enumerate(idx_DSP_diff[idx+1:]):\n",
    "                if next_idx_diff <2:\n",
    "                    idx_2_end = idx_DSP[idx+next_idx+2]\n",
    "                    temp_idx = idx + next_idx + 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            idxes_2_begin.append(idx_2_begin)\n",
    "            idxes_2_end.append(idx_2_end)\n",
    "\n",
    "    print(f\"Starting and ending indices list differ by {len(idxes_2_begin)-len(idxes_2_end)}\")\n",
    "    return idxes_2_begin, idxes_2_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp_colmns = ['T_stp_cool', 'T_stp_heat']\n",
    "for colm in stp_colmns:\n",
    "    idxes_2_begin, idxes_2_end = smooth_setpoints(df_read,colm)\n",
    "    for idx in range(0,len(idxes_2_begin)):\n",
    "        start_idx = idxes_2_begin[idx]\n",
    "        end_idx = idxes_2_end[idx]\n",
    "        \n",
    "        df_read.loc[start_idx:end_idx,colm] = df_read.iloc[end_idx][colm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Visualize setpoint data after stepoint smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idx = 0\n",
    "e_idx = 288\n",
    "f,axes = plt.subplots(2,1)\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_stp_cool'],label='cool', ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_stp_heat'],label='heat',ax = axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_ctrl'],label='T_in',ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['equip_run_cool'],label='cool_equip',ax =axes[1])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['equip_run_heat'],label='heat_equip', ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save smooth data seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.to_hdf('sample_data1_stp_processed.h5', key='df_read', mode='w',format=\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routine based habitual overrides\n",
    "Create a weekday dataframe specifically for extracting transition matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['mdsp'] = (df_read['T_stp_heat'].diff() != 0) | (df_read['T_stp_cool'].diff() != 0) & (df_read['event'] == 'Hold')\n",
    "df_read['dsp'] = (df_read['T_stp_heat'].diff() != 0) | (df_read['T_stp_cool'].diff() != 0)\n",
    "weekday_df = df_read.loc[df_read.DateTime.dt.weekday < 5].copy()\n",
    "weekend_df = df_read.loc[df_read.DateTime.dt.weekday > 5].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract transition matrices from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TM = []\n",
    "# for timestep in range(0,288):\n",
    "#     TM.append([timestep, 0, 0, 0])\n",
    "#     TM.append([timestep, 1, 0, 0])\n",
    "\n",
    "# TM = pd.DataFrame(TM,columns=['time','cur_state','p_2_0','p_2_1'])\n",
    "# TM = extract_TM_DyD(TM, weekday_df, df_read)\n",
    "# TM.to_csv('TM_habitual.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discomfort based override model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y = weekday_df['mdsp'].copy()\n",
    "X = weekday_df.drop('mdsp',axis=1).copy()\n",
    "X = X.drop(['DateTime','schedule','event','dsp','fan'],axis=1)\n",
    "print(X.columns)\n",
    "training, testing, training_labels, testing_labels = train_test_split(X, y, test_size = .25, random_state = 42)\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(training.values, training_labels.values)\n",
    "preds = clf.predict(testing.values)\n",
    "print(f\"Training score: {clf.score(training.values, training_labels.values)}\")\n",
    "print(f\"Testing score: {clf.score(testing.values, testing_labels.values)}\")\n",
    "print(f\"F1 score: {f1_score(testing_labels,preds)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_classification.pkl','wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest regression model to predict time to override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time to setpoint change for all dsps\n",
    "time_2_stp_change = np.diff(df_read.index[df_read.dsp == True]).tolist()\n",
    "time_2_stp_change.append(np.nan)\n",
    "time_2_stp_change = [item*5 for item in time_2_stp_change]\n",
    "\n",
    "df_read['mins_to_msc'] = np.nan*len(df_read)\n",
    "df_read.loc[df_read.index[df_read.dsp == True],'mins_to_msc'] = time_2_stp_change\n",
    "df_2hr_override = df_read.loc[df_read['mins_to_msc']<120].copy()\n",
    "# habitual model uses datetime as an input so ignoring these features here\n",
    "# df_2hr_override['year'] = df_read.DateTime.dt.year\n",
    "# df_2hr_override['day'] = df_read.DateTime.dt.day\n",
    "# df_2hr_override['hour'] = df_read.DateTime.dt.hour\n",
    "# df_2hr_override['day_of_week'] = df_read.DateTime.dt.weekday\n",
    "df_2hr_override = df_2hr_override.drop(['DateTime','schedule', 'event','fan'],axis=1)\n",
    "\n",
    "# One-hot encode the data using pandas get_dummies\n",
    "features = pd.get_dummies(df_2hr_override)\n",
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = features['mins_to_msc']\n",
    "features = features.drop(['mins_to_msc','dsp','mdsp'],axis=1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "print(feature_list)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'minutes')\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('RMSE:', mean_squared_error(test_labels,predictions,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('model_regressor.pkl','wb') as f:\n",
    "    pickle.dump(rf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(test_features[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(__file__))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.OccupantModel"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.OccupantModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('build_obm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b372945208ff69db1ee95b1179652dcd7f214cdc349312ee22ddf3c0a9829126"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
