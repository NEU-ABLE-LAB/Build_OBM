{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Tests for Build_OBM\n",
    "This file is meant to test out individual code before scripting in the main repo. Do not use for running the occupant behavior model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import csv\n",
    "import pickle\n",
    "from tools_ipynb import *\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ecobee data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a DyD file\n",
    "df = pd.read_csv(\"C:/devel/Build_OBM/data/home_1.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varInfo_1 = {'Unnamed: 0': 'DateTime' ,'Event': 'event' ,'Humidity': 'hum' ,'HumidityExpectedHigh': 'humExpHi' ,'HumidityExpectedLow': 'humExpLo' ,'RH_out': 'RH_out' ,'Remote_Sensor_1_Motion': 'RS1Mo' ,'Remote_Sensor_1_Temperature [oF]': 'RS1T' ,'Remote_Sensor_2_Motion': 'RS2Mo' ,'Remote_Sensor_2_Temperature [oF]': 'RS2T','Remote_Sensor_3_Motion': 'RS3Mo' ,'Remote_Sensor_3_Temperature [oF]': 'RS3T' ,'Remote_Sensor_4_Motion': 'RS4Mo' ,'Remote_Sensor_4_Temperature [oF]': 'RS4T' ,'Remote_Sensor_5_Motion': 'RS5Mo' ,'Remote_Sensor_5_Temperature [oF]': 'RS5T' ,'Remote_Sensor_6_Motion': 'RS6Mo' ,'Remote_Sensor_6_Temperature [oF]': 'RS6T' ,'Remote_Sensor_7_Motion': 'RS7Mo' ,'Remote_Sensor_7_Temperature [oF]': 'RS7T' ,'Remote_Sensor_8_Motion': 'RS8Mo' ,'Remote_Sensor_8_Temperature [oF]': 'RS8T','Remote_Sensor_9_Motion': 'RS9T' ,'Remote_Sensor_9_Temperature [oF]': 'RS9Mo' ,'Remote_Sensor_10_Motion': 'RS10T' ,'Remote_Sensor_10_Temperature [oF]': 'RS10Mo' ,'Remote_Sensor_11_Motion': 'RS11T' ,'Remote_Sensor_11_Temperature [oF]': 'RS11Mo' ,'Remote_Sensor_12_Motion': 'RS12T' ,'Remote_Sensor_12_Temperature [oF]': 'RS12Mo' ,'Remote_Sensor_13_Motion': 'RS13T' ,'Remote_Sensor_13_Temperature [oF]': 'RS13Mo' ,'Schedule': 'schedule' ,'T_ctrl [oF]': 'T_ctrl' ,'T_out [oF]': 'T_out' ,'T_stp_cool [oF]': 'T_stp_cool' ,'T_stp_heat [oF]': 'T_stp_heat' ,'Thermostat_Motion': 'TSMo' ,'Thermostat_Temperature [oF]': 'TST' ,'auxHeat1 [sec]': 'auxHeat1' ,'auxHeat2 [sec]': 'auxHeat2' ,'auxHeat3 [sec]': 'auxHeat3' ,'compCool1 [sec]': 'cmpCool1' ,'compCool2 [sec]': 'cmpCool2' ,'compCool3 [sec]': 'cmpCool3' ,'compHeat1 [sec]': 'cmpHeat1' ,'compHeat2 [sec]': 'cmpHeat2' ,'compHeat3 [sec]': 'cmpHeat3' ,'dehumidifier': 'dehumidifier','fan [sec]': 'fan' ,'humidifier': 'humidifier' ,'ventilator': 'ventilator'}\n",
    "varInfo = { 'Header in CSV':['Unnamed: 0', 'Event','Humidity', 'HumidityExpectedHigh', 'HumidityExpectedLow','RH_out','Remote_Sensor_1_Motion','Remote_Sensor_1_Temperature [oF]','Remote_Sensor_2_Motion','Remote_Sensor_2_Temperature [oF]','Remote_Sensor_3_Motion','Remote_Sensor_3_Temperature [oF]',\n",
    "'Remote_Sensor_4_Motion', 'Remote_Sensor_4_Temperature [oF]', 'Remote_Sensor_5_Motion', 'Remote_Sensor_5_Temperature [oF]', 'Remote_Sensor_6_Motion', 'Remote_Sensor_6_Temperature [oF]', 'Remote_Sensor_7_Motion', 'Remote_Sensor_7_Temperature [oF]', 'Remote_Sensor_8_Motion', 'Remote_Sensor_8_Temperature [oF]',\n",
    "'Remote_Sensor_9_Motion', 'Remote_Sensor_9_Temperature [oF]', 'Remote_Sensor_10_Motion', 'Remote_Sensor_10_Temperature [oF]', 'Remote_Sensor_11_Motion', 'Remote_Sensor_11_Temperature [oF]', 'Remote_Sensor_12_Motion', 'Remote_Sensor_12_Temperature [oF]', 'Remote_Sensor_13_Motion', 'Remote_Sensor_13_Temperature [oF]',\n",
    "'Schedule', 'T_ctrl [oF]', 'T_out [oF]', 'T_stp_cool [oF]', 'T_stp_heat [oF]', 'Thermostat_Motion', 'Thermostat_Temperature [oF]', 'auxHeat1 [sec]', 'auxHeat2 [sec]', 'auxHeat3 [sec]', 'compCool1 [sec]', 'compCool2 [sec]', 'compCool3 [sec]', 'compHeat1 [sec]', 'compHeat2 [sec]', 'compHeat3 [sec]', 'dehumidifier', 'fan [sec]',\n",
    "'humidifier', 'ventilator'],\n",
    " 'VariableName':['DateTime', 'event', 'hum', 'humExpHi','humExpLo' ,'RH_out' ,'RS1Mo' ,'RS1T' ,'RS2Mo' ,'RS2T' ,'RS3Mo' ,'RS3T' ,'RS4Mo' ,'RS4T' ,'RS5Mo' ,'RS5T' ,'RS6Mo' ,'RS6T' ,'RS7Mo' ,'RS7T' ,'RS8Mo' ,'RS8T',\n",
    " 'RS9Mo', 'RS9T' ,'RS10Mo' ,'RS10T' ,'RS11Mo' ,'RS11T' ,'RS12Mo' ,'RS12T' ,'RS13Mo' ,'RS13T' ,'schedule' ,'T_ctrl' ,'T_out' ,'T_stp_cool' ,'T_stp_heat' ,'TSMo' ,'TST' ,'auxHeat1' ,'auxHeat2' ,'auxHeat3' ,'cmpCool1' ,'cmpCool2' ,'cmpCool3' ,'cmpHeat1' ,'cmpHeat2' ,'cmpHeat3' ,'dehumidifier' ,'fan' ,'humidifier' ,'ventilator'],\n",
    " 'Type':['datetime', 'categorical', 'double', 'double','float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'categorical' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float' ,'float'],\n",
    " 'Unit':['', '', '%', '%','%' ,'%' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'' ,'oF' ,'oF' ,'oF' ,'oF' ,'' ,'F' ,'s' ,'s' ,'s' ,'s' ,'s' ,'s' ,'s' ,'s' ,'s' ,'' ,'s' ,'' ,''],\n",
    " 'Description':['Date and time that the reading was taken', 'Anything that modifies the schedule (e.g. A temperature hold, demand response event, Vacation, SmartRecovery feature)',\n",
    "                'Indoor humidity (in RH%)', 'Setpoint (for users who have a Humidifier) (in RH%)','Setpoint (for users who have a Humidifier) (in RH%)' ,'' ,'Detects motion (binary) at that date/time at the remote sensor 1' ,'Indoor temperature measurement at the remote sensor 1' ,'Detects motion (binary) at that date/time at the remote sensor 2' ,'Indoor temperature measurement at the remote sensor 2' ,'Detects motion (binary) at that date/time at the remote sensor 3' ,'Indoor temperature measurement at the remote sensor 3' ,'Detects motion (binary) at that date/time at the remote sensor 4' ,'Indoor temperature measurement at the remote sensor 4' ,'Detects motion (binary) at that date/time at the remote sensor 5' ,'Indoor temperature measurement at the remote sensor 5' ,'Detects motion (binary) at that date/time at the remote sensor 6' ,'Indoor temperature measurement at the remote sensor 6' ,'Detects motion (binary) at that date/time at the remote sensor 7' ,'Indoor temperature measurement at the remote sensor 7' ,'Detects motion (binary) at that date/time at the remote sensor 8' ,'Indoor temperature measurement at the remote sensor 8' ,'Detects motion (binary) at that date/time at the remote sensor 9' ,'Indoor temperature measurement at the remote sensor 9' ,'Detects motion (binary) at that date/time at the remote sensor 10' ,'Indoor temperature measurement at the remote sensor 10' ,'Detects motion (binary) at that date/time at the remote sensor 11' ,'Indoor temperature measurement at the remote sensor 11' ,'Detects motion (binary) at that date/time at the remote sensor 12' ,'Indoor temperature measurement at the remote sensor 12' ,'Detects motion (binary) at that date/time at the remote sensor 13' ,'Indoor temperature measurement at the remote sensor 13' ,'Fields include things like Vacation, Sleep, Away, Nap, etc. which are user-defined descriptors for desired set points against activity/behaviour' ,'Average indoor temperature based on relevant sensors as defined by the schedule or mode the user is in' ,'Outdoor temperate for nearest weather station' ,'Indoor cool setpoint' ,'Indoor heat setpoint' ,'Detects motion (binary) at that date/time' ,'Indoor measurement at the thermostat (I.e. Not remote sensor)' ,'Runtime (seconds) of stage 1 of any heat source other than a heat pump' ,'Runtime (seconds) of stage 2 of any heat source other than a heat pump' ,'Runtime (seconds) of stage 3 of any heat source other than a heat pump' ,'Runtime (seconds) for any cooling stage 1' ,'Runtime (seconds) for any cooling stage 2' ,'Runtime (seconds) for any cooling stage 3' ,'Runtime (seconds) for stage 1 of heat-pumps used in heating' ,'Runtime (seconds) for stage 2 of heat-pumps used in heating' ,'Runtime (seconds) for stage 3 of heat-pumps used in heating' ,'' ,'Runtime (seconds) for fan' ,'' ,'']}\n",
    "df_var = pd.DataFrame.from_dict(varInfo)\n",
    "df_var.set_index('Header in CSV',inplace=True)\n",
    "columns2replace = df_var['VariableName'].to_dict()\n",
    "df = df.rename(columns=columns2replace)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add motion column that aggregates all motion data into a boolean value\n",
    "def agg_data(columns,row):\n",
    "    return row[columns].any()\n",
    "\n",
    "motion_colmns =[x for x in df.columns if 'Mo' in x]\n",
    "df['mo'] = df.apply(lambda row: agg_data(motion_colmns,row), axis=1)\n",
    "heating_equip_columns = ['auxHeat1' ,'auxHeat2' ,'auxHeat3','cmpHeat1' ,'cmpHeat2' ,'cmpHeat3']\n",
    "cooling_equip_columns = ['cmpCool1' ,'cmpCool2' ,'cmpCool3']\n",
    "heat_colmns = [x for x in df.columns if x in heating_equip_columns]\n",
    "cool_colmns = [x for x in df.columns if x in cooling_equip_columns]\n",
    "\n",
    "# 'auxHeat1' ,'auxHeat2' ,'auxHeat3' ,'cmpCool1' ,'cmpCool2' ,'cmpCool3' ,'cmpHeat1' ,'cmpHeat2' ,'cmpHeat3' \n",
    "df['equip_run_heat'] = df.apply(lambda row: agg_data(heat_colmns,row), axis=1)\n",
    "df['equip_run_cool'] = df.apply(lambda row: agg_data(cool_colmns,row), axis=1)\n",
    "# Change string series to datetime series\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df['schedule'] = df['schedule'].astype(\"category\")\n",
    "df['event'] = df['event'].astype(\"category\")\n",
    "df_new = df.copy()\n",
    "cols_2_keep = ['DateTime', 'schedule', 'event', 'T_ctrl', 'T_stp_cool', 'T_stp_heat',\n",
    "       'hum', 'T_out', 'equip_run_heat','equip_run_cool', 'fan','mo']\n",
    "df_new.drop(df_new.columns.difference(cols_2_keep), 1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/read to/from hdf5 format for easy load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_hdf('sample_data1.h5', key='df_new', mode='w',format=\"table\")\n",
    "del [[df,df_new]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_hdf('sample_data1.h5')\n",
    "df_read.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## EDA: Visualize setpoint data prior to cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idx = 0\n",
    "e_idx = 100\n",
    "f,axes = plt.subplots(3,1)\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_stp_cool'],label='cool', ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_stp_heat'],label='heat',ax = axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_ctrl'],label='T_in',ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_out'],label='T_out',ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['equip_run_cool'],label='cool_equip',ax =axes[1])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['equip_run_heat'],label='heat_equip', ax=axes[1])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['mo'],label='heat_equip', ax=axes[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_setpoints(df,column):\n",
    "    idx_DSP = df[df[column].diff() != 0].index.values\n",
    "    idx_DSP_diff = np.diff(idx_DSP)\n",
    "    idxes_2_begin = []\n",
    "    idxes_2_end = []\n",
    "    temp_idx = -1\n",
    "    # Iterate over the difference of index values were dsp was found\n",
    "    for idx, diff_value in enumerate(idx_DSP_diff):\n",
    "        if idx <= temp_idx:\n",
    "            continue\n",
    "        \n",
    "        # If the DSPs exists closely\n",
    "        if diff_value < 3:\n",
    "\n",
    "            idx_2_begin = idx_DSP[idx]\n",
    "            idx_2_end = idx_DSP[idx+1]\n",
    "            # Scan when the last consecutive DSP occurs\n",
    "            for next_idx, next_idx_diff in enumerate(idx_DSP_diff[idx+1:]):\n",
    "                if next_idx_diff <2:\n",
    "                    idx_2_end = idx_DSP[idx+next_idx+2]\n",
    "                    temp_idx = idx + next_idx + 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            idxes_2_begin.append(idx_2_begin)\n",
    "            idxes_2_end.append(idx_2_end)\n",
    "\n",
    "    print(f\"Starting and ending indices list differ by {len(idxes_2_begin)-len(idxes_2_end)}\")\n",
    "    return idxes_2_begin, idxes_2_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp_colmns = ['T_stp_cool', 'T_stp_heat']\n",
    "for colm in stp_colmns:\n",
    "    idxes_2_begin, idxes_2_end = smooth_setpoints(df_read,colm)\n",
    "    for idx in range(0,len(idxes_2_begin)):\n",
    "        start_idx = idxes_2_begin[idx]\n",
    "        end_idx = idxes_2_end[idx]\n",
    "        \n",
    "        df_read.loc[start_idx:end_idx,colm] = df_read.iloc[end_idx][colm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EDA: Visualize setpoint data after stepoint smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idx = 0\n",
    "e_idx = 288\n",
    "f,axes = plt.subplots(2,1)\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_stp_cool'],label='cool', ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_stp_heat'],label='heat',ax = axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['T_ctrl'],label='T_in',ax=axes[0])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['equip_run_cool'],label='cool_equip',ax =axes[1])\n",
    "sns.lineplot(x=df_read.loc[s_idx:e_idx]['DateTime'],y=df_read.loc[s_idx:e_idx]['equip_run_heat'],label='heat_equip', ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save smooth data seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.to_hdf('sample_data1_stp_processed.h5', key='df_read', mode='w',format=\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routine based habitual overrides\n",
    "Create a weekday dataframe specifically for extracting transition matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read['mdsp'] = (df_read['T_stp_heat'].diff() != 0) | (df_read['T_stp_cool'].diff() != 0) & (df_read['event'] == 'Hold')\n",
    "df_read['dsp'] = (df_read['T_stp_heat'].diff() != 0) | (df_read['T_stp_cool'].diff() != 0)\n",
    "weekday_df = df_read.loc[df_read.DateTime.dt.weekday < 5].copy()\n",
    "weekend_df = df_read.loc[df_read.DateTime.dt.weekday > 5].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract transition matrices from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TM = []\n",
    "for timestep in range(1,289):\n",
    "    TM.append([timestep, 0, 0, 0])\n",
    "    TM.append([timestep, 1, 0, 0])\n",
    "\n",
    "TM = pd.DataFrame(TM,columns=['time','cur_state','p_2_0','p_2_1'])\n",
    "TM = extract_TM_DyD(TM, weekday_df, df_read)\n",
    "TM.to_csv('TM_habitual.csv',index=False)\n",
    "TM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load 2nd order Markov model TMs from MATLAB output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TM_cool_wd = pd.read_csv(\"C:\\devel\\ecobee_mental_models\\data\\TMs\\cool_wd.csv\")\n",
    "TM_cool_we = pd.read_csv(\"C:\\devel\\ecobee_mental_models\\data\\TMs\\cool_we.csv\")\n",
    "TM_heat_wd = pd.read_csv(\"C:\\devel\\ecobee_mental_models\\data\\TMs\\heat_wd.csv\")\n",
    "TM_heat_we = pd.read_csv(\"C:\\devel\\ecobee_mental_models\\data\\TMs\\heat_we.csv\")\n",
    "TMs = {'cool_wd':TM_cool_wd, 'cool_we':TM_cool_we, 'heat_wd':TM_heat_wd, 'heat_we':TM_heat_we}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMs['cool_we'],TMs['cool_wd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 1\n",
    "current_state = 0\n",
    "prev_state = 1\n",
    "\n",
    "df_TM.loc[(df_TM['timestep'] == timestep + 1) & (df_TM['prev_state'] == prev_state) & (df_TM['cur_state'] == current_state), 'p_2_0':'p_2_1'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = om_tools.datetime.datetime(2019, 1, 1, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discomfort based override model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y = weekday_df['mdsp'].copy()\n",
    "X = weekday_df.drop('mdsp',axis=1).copy()\n",
    "X = X.drop(['DateTime','schedule','event','dsp','fan'],axis=1)\n",
    "print(X.columns)\n",
    "training, testing, training_labels, testing_labels = train_test_split(X, y, test_size = .25, random_state = 42)\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(training.values, training_labels.values)\n",
    "preds = clf.predict(testing.values)\n",
    "print(f\"Training score: {clf.score(training.values, training_labels.values)}\")\n",
    "print(f\"Testing score: {clf.score(testing.values, testing_labels.values)}\")\n",
    "print(f\"F1 score: {f1_score(testing_labels,preds)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_classification.pkl','wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest regression model to predict time to override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time to setpoint change for all dsps\n",
    "time_2_stp_change = np.diff(df_read.index[df_read.dsp == True]).tolist()\n",
    "time_2_stp_change.append(np.nan)\n",
    "time_2_stp_change = [item*5 for item in time_2_stp_change]\n",
    "\n",
    "df_read['mins_to_msc'] = np.nan*len(df_read)\n",
    "df_read.loc[df_read.index[df_read.dsp == True],'mins_to_msc'] = time_2_stp_change\n",
    "df_2hr_override = df_read.loc[df_read['mins_to_msc']<120].copy()\n",
    "# habitual model uses datetime as an input so ignoring these features here\n",
    "# df_2hr_override['year'] = df_read.DateTime.dt.year\n",
    "# df_2hr_override['day'] = df_read.DateTime.dt.day\n",
    "# df_2hr_override['hour'] = df_read.DateTime.dt.hour\n",
    "# df_2hr_override['day_of_week'] = df_read.DateTime.dt.weekday\n",
    "df_2hr_override = df_2hr_override.drop(['DateTime','schedule', 'event','fan'],axis=1)\n",
    "\n",
    "# One-hot encode the data using pandas get_dummies\n",
    "features = pd.get_dummies(df_2hr_override)\n",
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = features['mins_to_msc']\n",
    "features = features.drop(['mins_to_msc','dsp','mdsp'],axis=1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "print(feature_list)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'minutes')\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('RMSE:', mean_squared_error(test_labels,predictions,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('model_regressor.pkl','wb') as f:\n",
    "    pickle.dump(rf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(test_features[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(__file__))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datetime.datetime(2019, 1, 1, 0, 0, 0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x + datetime.timedelta(minutes=30)).minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Import and implement mscpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import csv\n",
    "import pickle\n",
    "from tools_ipynb import *\n",
    "import pathlib\n",
    "import datetime\n",
    "mscpd_dir = pathlib.Path(\"C:\\devel\\Build_OBM\\input_data\\csv\").resolve()\n",
    "cd = datetime.datetime(2019, 1, 1, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = list(mscpd_dir.iterdir())\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_data = {}\n",
    "for file in files:\n",
    "    init_data[file.stem] = pd.read_csv(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sorted(init_data, key=len, reverse=False)\n",
    "list(init_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = 'heat_wd'\n",
    "season_label = 'heat'\n",
    "N = init_data[label+'_Nmscpd']['N'].values\n",
    "prob = init_data[label+'_Nmscpd']['prob'].values\n",
    "if np.sum(prob) != 1:\n",
    "    diff = abs(1 - np.sum(prob))\n",
    "    prob[0] = prob[0] + diff\n",
    "\n",
    "N_mscpd = np.random.choice(N, p = prob)\n",
    "N_mscpd = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Realize the time of first msc i.e. t_msc_1\n",
    "tod = init_data[label + '_' + str(N_mscpd) + 'mscpd_tod1']['tod'].values\n",
    "prob = init_data[label + '_' + str(N_mscpd) + 'mscpd_tod1']['prob'].values\n",
    "if np.sum(prob) != 1:\n",
    "    diff = abs(1 - np.sum(prob))\n",
    "    prob[0] = prob[0] + diff\n",
    "\n",
    "t_msc_1 = np.random.choice(tod, p = prob)\n",
    "t_msc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Realize the type of first msc i.e. type_msc_1\n",
    "types_1 = init_data[label + '_' + str(N_mscpd) + 'mscpd_type1']['types'].values\n",
    "prob = init_data[label + '_' + str(N_mscpd) + 'mscpd_type1']['prob'].values\n",
    "if np.sum(prob) != 1:\n",
    "    diff = abs(1 - np.sum(prob))\n",
    "    prob[0] = prob[0] + diff\n",
    "\n",
    "type_1 = np.random.choice(types_1, p = prob)\n",
    "type_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Realize the degree of first msc i.e. DOMSC_1 given time and type of first msc i.e. t_msc_1 and type_1 \n",
    "data = init_data[label + '_' + str(N_mscpd) + 'mscpd_'+ season_label + '_DOO1_'+ type_1 +'_type']\n",
    "DOMSCs_1 = np.array(data.columns[1:]).astype(int)\n",
    "prob = np.array(data.loc[data['tod'] == t_msc_1].values[0][1:]).astype(float)\n",
    "if np.sum(prob) != 1:\n",
    "    diff = abs(1 - np.sum(prob))\n",
    "    prob[0] = prob[0] + diff\n",
    "\n",
    "domsc_1 = np.random.choice(DOMSCs_1, p = prob)\n",
    "domsc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.loc[data['tod'] == t_msc_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Realize the time of second msc i.e. t_msc_2 given the time of first msc i.e., t_msc_1\n",
    "data = init_data[label + '_' + str(N_mscpd) + 'mscpd_tod2_tod1']\n",
    "tod_2 = init_data[label + '_' + str(N_mscpd) + 'mscpd_tod2_tod1']['tod']\n",
    "prob = np.array(data.loc[data.tod == t_msc_1].values[0][1:]).astype(float)\n",
    "if np.sum(prob) != 1:\n",
    "    diff = abs(1 - np.sum(prob))\n",
    "    prob[0] = prob[0] + diff\n",
    "\n",
    "t_msc_2 = np.random.choice(tod_2, p = prob)\n",
    "t_msc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Realize the type of second msc i.e. type_msc_2 given the type of first msc i.e. type_1\n",
    "types_2 = init_data[label + '_' + str(N_mscpd) + 'mscpd_type2_type1_' + type_1]['types'].values\n",
    "prob = init_data[label + '_' + str(N_mscpd) + 'mscpd_type2_type1_' + type_1]['prob'].values\n",
    "if np.sum(prob) != 1:\n",
    "    diff = abs(1 - np.sum(prob))\n",
    "    prob[0] = prob[0] + diff\n",
    "\n",
    "type_2 = np.random.choice(types_2, p = prob)\n",
    "type_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Realize the degree of second msc i.e. DOO_msc_2 given the type and degree of first msc and type of second msc i.e. type_1, DOMSC_1, type_2\n",
    "data = init_data[label + '_' + str(N_mscpd) + 'mscpd_row' + season_label + '_col' + season_label + '_DOO2_' + type_1 + '_type1_' + type_2 + '_type2']\n",
    "DOMSCs_2 = np.array(data.columns[1:]).astype(int)\n",
    "prob = np.array(data.loc[data['doo'] == DOMSC_1].values[0][1:]).astype(float)\n",
    "if np.sum(prob) != 1:\n",
    "    diff = abs(1 - np.sum(prob))\n",
    "    prob[0] = prob[0] + diff\n",
    "\n",
    "domsc_2 = np.random.choice(DOMSCs_2, p = prob)\n",
    "domsc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "routine_msc_schedule = pd.DataFrame([], columns=['TOD','delT_cool','delT_heat'])\n",
    "routine_msc_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "season = 'heat'\n",
    "if season == 'cool':\n",
    "    routine_msc_schedule.TOD = [t_msc_1,t_msc_2]\n",
    "    routine_msc_schedule.delT_cool = [domsc_1,domsc_2]\n",
    "    routine_msc_schedule.delT_heat = [0,0]\n",
    "    routine_msc_schedule.TOD = pd.to_datetime(routine_msc_schedule.TOD, format='%H:%M:%S').dt.time\n",
    "    \n",
    "elif season == 'heat':\n",
    "    routine_msc_schedule.TOD = [t_msc_1,t_msc_2]\n",
    "    routine_msc_schedule.delT_cool = [0,0]\n",
    "    routine_msc_schedule.delT_heat = [domsc_1,domsc_2]\n",
    "    routine_msc_schedule.TOD = pd.to_datetime(routine_msc_schedule.TOD, format='%H:%M:%S').dt.time\n",
    "\n",
    "routine_msc_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "routine_msc_schedule.TOD.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "routine_msc_schedule.TOD == cd.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetime.datetime(2019, 1, 1, 10, 40, 0):datetime.timedelta('minutes'=5):datetime.datetime(2019, 1, 1, 23, 59, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "np.arange(cd, cd+timedelta(hours=24), timedelta(minutes=1)).astype(datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd.time() = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.to_datetime([t_msc_1,t_msc_2], format='%H:%M:%S').time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetime.combine([cd.date(), cd.date()], pd.to_datetime([t_msc_1,t_msc_2], format='%H:%M:%S').time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetime.combine(cd.date(),pd.to_datetime(t_msc_1, format='%H:%M:%S').time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.datetime.combine(cd.date(),pd.to_datetime(t_msc_1, format='%H:%M:%S').time())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.arange(cd, cd+datetime.timedelta(hours=24), datetime.timedelta(minutes=5)).astype(datetime.datetime)\n",
    "# occupancy = np.random.choice(x,100)\n",
    "# occupancy\n",
    "type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "occupancy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Realize the time of first msc i.e. t_msc_1\n",
    "t_msc_1=None\n",
    "while t_msc_1 not in occupancy:\n",
    "    # Realize the time of first msc i.e. t_msc_1\n",
    "    data = init_data[label + '_' + str(N_mscpd) + 'mscpd_tod1']\n",
    "    tod_1 = data['tod'].values\n",
    "    prob = data['prob'].values\n",
    "    if np.sum(prob) != 1:\n",
    "        diff = abs(1 - np.sum(prob))\n",
    "        prob[0] = prob[0] + diff\n",
    "    t_msc_1 = datetime.datetime.combine(cd.date(), pd.to_datetime(np.random.choice(tod_1, p = prob), format='%H:%M:%S').time())\n",
    "t_msc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "any(t_msc_1 == occupancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_msc_1 == occupancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_msc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "occupancy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_msc_1 not in occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame([], columns=['TOD','delT_cool','delT_heat'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.TOD = [t_msc_1,t_msc_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.set_index("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.TOD.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.TOD = pd.Series(x.TOD.dt.to_pydatetime(),dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing matlab files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comfort dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_mat_2_pickle_comf(filepath):\n",
    "    # filepath = pathlib.Path('C:/devel/ecobee_mental_models/data/comf_Occup1_30_min_filter_py.mat').resolve()\n",
    "    mat = scipy.io.loadmat(file)\n",
    "    columns = []\n",
    "    total_n_homes = len(mat['comfCellLabels_py'])\n",
    "    df = pd.DataFrame([])\n",
    "    vec_clms = ['T_ctrl_vec', 'T_stp_cool_vec', 'T_stp_heat_vec', 'T_tst_vec', 'T_out_vec','hum_vec']\n",
    "    duration_clms =  ['len','occDt_b4dsp','prevLen']\n",
    "    categorical_clms = ['event', 'schedule','prevSchedule','StpTransition','prevEvent']\n",
    "    datetime_clms = ['DateTime']\n",
    "    for home_n in range(0,total_n_homes):\n",
    "        if home_n%100 == 0:\n",
    "            print(home_n, end=',')\n",
    "        home_ID = mat['comfIDs_py'][home_n]\n",
    "        temp_data = {}\n",
    "\n",
    "        # Skip if no datetime values exist for a home\n",
    "        if len(mat['comfCells_py'][home_n][0][0][0]) == 0:\n",
    "            continue\n",
    "\n",
    "        for column_n in range(0, len(mat['comfCellLabels_py'][home_n][0][0])):\n",
    "            column_name = mat['comfCellLabels_py'][home_n][0][0][column_n][0]\n",
    "\n",
    "            if column_name in datetime_clms + categorical_clms + duration_clms + vec_clms:\n",
    "                if column_name in datetime_clms:\n",
    "                    temp_data[column_name] = pd.to_datetime(mat['comfCells_py'][home_n][0][0][column_n])\n",
    "                elif column_name in categorical_clms:\n",
    "                    temp_data[column_name] = [i.replace(\" \",\"\") for i in mat['comfCells_py'][home_n][0][0][column_n]]\n",
    "                elif column_name in duration_clms:\n",
    "                    temp_data[column_name] = []\n",
    "                    for item in mat['comfCells_py'][home_n][0][0][column_n]:\n",
    "                        if str(type(item)) == \"<class 'numpy.str_'>\":\n",
    "                            if item.replace(' ','').lower() == 'nan':\n",
    "                                item = float(\"nan\")\n",
    "                            else:\n",
    "                                item = int(item.replace(' ','').split(':')[0])*60 + int(item.replace(' ','').split(':')[1])\n",
    "                        elif str(type(item)) == \"<class 'numpy.ndarray'>\":\n",
    "                            item = mat['comfCells_py'][home_n][0][0][column_n][0][0]\n",
    "                        else:\n",
    "                            raise ValuError('check dtype')\n",
    "                        temp_data[column_name].append(item)                    \n",
    "                elif column_name in vec_clms:\n",
    "                    temp_data[column_name] = [np.asarray([float('nan') if len(item) == 0 else item[0] for item in msc[0]], dtype=np.float32) for msc in mat['comfCells_py'][home_n][0][0][column_n]]\n",
    "                else:\n",
    "                    print('Datatype not found')\n",
    "            else:\n",
    "                temp_data[column_name] = [float(i[0]) for i in mat['comfCells_py'][home_n][0][0][column_n]]\n",
    "        temp_data['ID'] = home_ID\n",
    "        temp_data = pd.DataFrame.from_dict(temp_data)        \n",
    "        df = pd.concat([df,temp_data], axis=0, ignore_index=True)\n",
    "    print(df.memory_usage())\n",
    "    df.to_pickle(\"./comf_df.pkl\")\n",
    "    \n",
    "    \n",
    "df_comf =pd.read_pickle(\"./comf_df.pkl\")\n",
    "df_comf_tf = df_comf[['DateTime','T_ctrl', 'T_stp_cool', 'T_stp_heat','TST', 'mo', 'len', 'occDt_b4dsp', 'prevT_ctrl','total_occup_mins',\n",
    "            'prevT_stp_sc_cool', 'prevT_stp_sc_heat', 'prevT_ctrl_sc', 'prevT_stp_cool', 'prevT_stp_heat', 'StpTransition', 'T_ctrl_vec','ID']].copy()\n",
    "filter = (df_comf_tf.T_stp_cool  - df_comf_tf.prevT_stp_cool < 0) & (~df_comf_tf['occDt_b4dsp'].isnull()) & (df_comf_tf.StpTransition.values == 'Cool2Cool')\n",
    "df_comf_tf_cool = df_comf_tf.loc[filter].reset_index().copy()\n",
    "TF = []\n",
    "T_c = df_comf_tf_cool['T_ctrl'].mean()\n",
    "for index,row in df_comf_tf_cool.iterrows():\n",
    "    # T_c = row['prevT_stp_sc_cool']\n",
    "    T_in = row['T_ctrl_vec']\n",
    "    a = 1\n",
    "    b = 1\n",
    "    tf_1 = 0\n",
    "    for k in range(0,len(T_in)):\n",
    "        if k == 0:\n",
    "            tf_1 = 0\n",
    "        else:\n",
    "            tf_1 = a*tf_1 + b*(T_in[k] - T_c)\n",
    "    TF.append(tf_1)\n",
    "df_comf_tf_cool['TF'] = TF\n",
    "df_comf_tf_cool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_mat_2_pickle_msc(filepath):\n",
    "    file = pathlib.Path('C:\\devel\\ecobee_mental_models\\data\\mdsp_Occup1v10_occupB4prevDSP(30 min-Occup_filter)AfterprevLenbug_T_ctrlvec_py.mat').resolve()\n",
    "    mat = scipy.io.loadmat(file)\n",
    "    total_n_homes = len(mat['mdspCellLabels_py'])\n",
    "    df = pd.DataFrame([])\n",
    "    vec_clms = ['T_ctrl_vec', 'T_stp_cool_vec', 'T_stp_heat_vec', 'T_tst_vec', 'T_out_vec']\n",
    "    duration_clms =  ['len','occDt','occDt_b4dsp','prevLen','nextLen']\n",
    "    categorical_clms = ['event', 'schedule','type','StpTransition','prevEvent','nextEvent']\n",
    "    datetime_clms = ['DateTime']\n",
    "\n",
    "    for home_n in range(0,total_n_homes):\n",
    "        if home_n%100 == 0:\n",
    "            print(home_n, end=',')\n",
    "        home_ID = mat['mdspIDs_py'][home_n]\n",
    "        temp_data = {}\n",
    "\n",
    "        # Skip if no datetime values exist for a home\n",
    "        if len(mat['mdspCells_py'][home_n][0][0][0]) == 0:\n",
    "            continue\n",
    "\n",
    "        for column_n in range(0, len(mat['mdspCellLabels_py'][home_n][0][0])):\n",
    "            column_name = mat['mdspCellLabels_py'][home_n][0][0][column_n][0]\n",
    "\n",
    "            if column_name in datetime_clms + categorical_clms + duration_clms + vec_clms:\n",
    "                if column_name in datetime_clms:\n",
    "                    temp_data[column_name] = pd.to_datetime(mat['mdspCells_py'][home_n][0][0][column_n])\n",
    "                elif column_name in categorical_clms:\n",
    "                    temp_data[column_name] = [i.replace(\" \",\"\") for i in mat['mdspCells_py'][home_n][0][0][column_n]]\n",
    "                elif column_name in duration_clms:\n",
    "                    temp_data[column_name] = []\n",
    "                    for item in mat['mdspCells_py'][home_n][0][0][column_n]:\n",
    "                        if str(type(item)) == \"<class 'numpy.str_'>\":\n",
    "                            if item.replace(' ','').lower() == 'nan':\n",
    "                                item = float(\"nan\")\n",
    "                            else:\n",
    "                                item = int(item.replace(' ','').split(':')[0])*60 + int(item.replace(' ','').split(':')[1])\n",
    "                        elif str(type(item)) == \"<class 'numpy.ndarray'>\":\n",
    "                            item = mat['mdspCells_py'][home_n][0][0][column_n][0][0]\n",
    "                        else:\n",
    "                            raise ValuError('check dtype')\n",
    "                        temp_data[column_name].append(item)                    \n",
    "                elif column_name in vec_clms:\n",
    "                    temp_data[column_name] = [np.asarray([float('nan') if len(item) == 0 else item[0] for item in msc[0]], dtype=np.float32) for msc in mat['mdspCells_py'][home_n][0][0][column_n]]\n",
    "                else:\n",
    "                    print('Datatype not found')\n",
    "            else:\n",
    "                temp_data[column_name] = [i[0] for i in mat['mdspCells_py'][home_n][0][0][column_n]]\n",
    "        temp_data['ID'] = home_ID\n",
    "        temp_data = pd.DataFrame.from_dict(temp_data)        \n",
    "        df = pd.concat([df,temp_data], axis=0, ignore_index=True)\n",
    "    print(df.memory_usage())\n",
    "    df.to_pickle(\"./mdsp_df.pkl\")\n",
    "    \n",
    "df_msc =pd.read_pickle(\"./mdsp_df.pkl\")\n",
    "df_msc_tf = df_msc[['DateTime','T_ctrl', 'T_stp_cool', 'T_stp_heat','TST', 'mo', 'len', 'occDt', 'occDt_b4dsp', 'type', 'prevT_ctrl',\n",
    "            'prevT_stp_sc_cool', 'prevT_stp_sc_heat', 'prevT_ctrl_sc', 'prevT_stp_cool', 'prevT_stp_heat', 'StpTransition', 'T_ctrl_vec','ID']].copy()\n",
    "filter = (df_msc_tf.T_stp_cool  - df_msc_tf.prevT_stp_cool < 0) & (~df_msc_tf['occDt_b4dsp'].isnull()) & (df_msc_tf.StpTransition.values == 'Cool2Cool')\n",
    "df_msc_tf_cool = df_msc_tf.loc[filter].reset_index().copy()\n",
    "TF = []\n",
    "T_c = df_comf_tf_cool['T_ctrl'].mean()\n",
    "for index,row in df_msc_tf_cool.iterrows():\n",
    "    # T_c = row['prevT_stp_sc_cool']\n",
    "    T_in = row['T_ctrl_vec']\n",
    "    a = 1\n",
    "    b = 1\n",
    "    tf_1 = 0\n",
    "    for k in range(0,len(T_in)):\n",
    "        if k == 0:\n",
    "            tf_1 = 0\n",
    "        else:\n",
    "            tf_1 = a*tf_1 + b*(T_in[k] - T_c)\n",
    "    TF.append(tf_1)\n",
    "df_msc_tf_cool['TF'] = TF\n",
    "df_msc_tf_cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.histplot(data = df_tf_cool['T_ctrl'],binwidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_tf_cool['T_ctrl'].mean(),df_tf_cool['T_ctrl'].median(),df_tf_cool['T_ctrl'].mode(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Build_obm",
   "language": "python",
   "name": "build_obm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b372945208ff69db1ee95b1179652dcd7f214cdc349312ee22ddf3c0a9829126"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
